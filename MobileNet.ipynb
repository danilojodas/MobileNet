{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4N88SJ0PXWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "def relu6(inputs):\n",
        "    '''\n",
        "        Performs the ReLU6 activation function for the bottleneck stage of the MobileNet V2\n",
        "        Inputs:\n",
        "            inputs: the layer with the inputs for the activation function\n",
        "        Return:\n",
        "            Min value between the value of the regular ReLU function and 6\n",
        "    '''\n",
        "    \n",
        "    return K.relu(inputs,max_value=6)\n",
        "\n",
        "def bottleneck(inputs, t, alpha, num_filters, kernel_sz=(3,3),stride=(1,1),pad='same',residual=False,dropout=False,dropout_perc=0.1):    \n",
        "    '''\n",
        "        Performs the bottleneck stage of the MobileNet V2\n",
        "        Inputs:\n",
        "            inputs: the layer with the inputs\n",
        "            t: the value used to increase the number of filters of the expansion stage\n",
        "            alpha: width multiplier that controls the number of filters of the output tensor\n",
        "            num_filters: number of filters of the output tensor\n",
        "            kernel_sz = kernel size of the filter\n",
        "            stride: stride of the kernel\n",
        "            pad: padding of the filter\n",
        "            residual: parameter that determine the sum of the input and output of the bottleneck stage\n",
        "            dropout: determine if dropout will be performed \n",
        "            dropout_perc: percentage of neurons that will be set to zero\n",
        "        Return:\n",
        "            x: the result of the bottleneck stage\n",
        "    '''    \n",
        "    \n",
        "    # Get the index of the input 4D tensor that represents the number of channels of the image\n",
        "    # -1 can also represent the last element of the tensor\n",
        "    channel_idx = 1 if K.image_data_format == 'channels_first' else -1\n",
        "    \n",
        "    # Number of filters for the expansion convolution\n",
        "    num_filters_exp = K.int_shape(inputs)[channel_idx] * t    \n",
        "    \n",
        "    # Number of filters of the projection convolution\n",
        "    num_filters_proj = int(num_filters * alpha)\n",
        "    \n",
        "    # Expansion layer\n",
        "    x = Conv2D(filters=num_filters_exp,kernel_size=(1,1),strides=(1,1),padding=pad)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(relu6)(x)\n",
        "    \n",
        "    # Depthwise convolution\n",
        "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(relu6)(x)\n",
        "    \n",
        "    # Projection convolution\n",
        "    x = Conv2D(filters=num_filters_proj,kernel_size=(1,1),strides=(1,1),padding=pad)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    if (residual == True):\n",
        "        x = Add()([x,inputs])\n",
        "        \n",
        "    if (dropout == True):\n",
        "      x = Dropout(dropout_perc)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def depthwise_block(inputs,stride,kernel_sz=(3,3),pad='same'):\n",
        "    '''\n",
        "        Function that performs the depthwise convolution\n",
        "        Inputs:\n",
        "            inputs:    the input shape of the depthwise convolution\n",
        "            kernel_sz: a tuple that indicates the size of the filtering kernel\n",
        "            stride:    a tuple that indicates the strides of the kernel\n",
        "        Return:\n",
        "            x: the result of the depthwise convolution\n",
        "    '''\n",
        "        \n",
        "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "        \n",
        "    return x\n",
        "\n",
        "def pointwise_block(inputs,num_filters,alpha,kernel_sz=(1,1),stride=(1,1),pad='same',dropout=False,dropout_perc=0.1):\n",
        "    '''\n",
        "        Function that performs the pointwise convolution\n",
        "        Inputs:\n",
        "            inputs:      the input shape of the depthwise convolution\n",
        "            num_filters: number of filters to be used in the convolution\n",
        "            kernel_sz:   a tuple that indicates the size of the filtering kernel\n",
        "            stride:      a tuple that indicates the strides of the kernel\n",
        "            dropout: determine if dropout will be performed \n",
        "            dropout_perc: percentage of neurons that will be set to zero            \n",
        "        Return:\n",
        "            x: the result of the pointwise convolution\n",
        "    '''    \n",
        "    \n",
        "    # Number of filters based on width multiplier reported in the original paper\n",
        "    n_fil = int(num_filters * alpha)    \n",
        "    \n",
        "    x = Conv2D(filters=n_fil,kernel_size=kernel_sz,padding=pad)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "    \n",
        "    if (dropout == True):\n",
        "      x = Dropout(dropout_perc)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def MobileNetV1(input_shape,num_units,filters=32,kernel_sz=(3,3),stride=(2,2),alp=1,ro=1,dropout_perc=0.1):\n",
        "    input_shape = (int(input_shape[0] * ro), int(input_shape[1] * ro), input_shape[2])\n",
        "    \n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    # Regular convolution\n",
        "    x = Conv2D(filters=filters,kernel_size=kernel_sz,strides=stride)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "    x = Dropout(dropout_perc)(x)\n",
        "    \n",
        "    # First depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=64,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Second depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = pointwise_block(x,num_filters=128,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Third depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=128,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Fourth depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = pointwise_block(x,num_filters=256,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)    \n",
        "    \n",
        "    # Fifth depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=256,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "\n",
        "    # Sixth depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Seventh depthwise-pointwise block (repeated five times)\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=512,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc) \n",
        "    \n",
        "    # Eight depthwise-pointwise block\n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = pointwise_block(x,num_filters=1024,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "\n",
        "    # Nineth depthwise-pointwise block    \n",
        "    x = depthwise_block(x,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = pointwise_block(x,num_filters=1024,alpha=alp,stride=(1,1),dropout=True,dropout_perc=dropout_perc)    \n",
        "    \n",
        "    # Pooling layer\n",
        "    # Pooling size correction due to the resolution multiplier parameter\n",
        "    pool_size = int(np.round(7*ro))\n",
        "    x = AveragePooling2D(padding='valid',pool_size=(pool_size,pool_size),strides=(1,1))(x)    \n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    # Fully connected layer\n",
        "    x = Dense(units=1024,activation='relu')(x)\n",
        "    \n",
        "    # Softmax layer\n",
        "    output = Dense(num_units,activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs,output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def MobileNetV2(input_shape, num_units, filters=32, kernel_sz=(3,3),stride=(2,2),alp=1,ro=1,dropout_perc=0.1):\n",
        "    input_shape = (int(input_shape[0] * ro), int(input_shape[1] * ro), input_shape[2])\n",
        "    \n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    # Regular convolution\n",
        "    x = Conv2D(filters=filters,kernel_size=kernel_sz,strides=stride)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(relu6)(x)\n",
        "    x = Dropout(dropout_perc)(x)\n",
        "\n",
        "    # First bottleneck convolution\n",
        "    x = bottleneck(x,t=1,alpha=alp,num_filters=16,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "\n",
        "    # Second bottleneck convolution (peformed 2 times)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(2,2),dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Third bottleneck convolution (peformed 3 times)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Fourth bottleneck convolution (performed 4 times)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Fifth bottleneck convolution (performed 3 times)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1))\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Sixth bottleneck convolution (performed 3 times)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(2,2))\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Seventh bottleneck convolution (performed 1 time)\n",
        "    x = bottleneck(x,t=6,alpha=alp,num_filters=320,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
        "    \n",
        "    # Eigth layer (regular convolution)\n",
        "    x = Conv2D(filters=1280, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
        "    \n",
        "    # Pooling layer\n",
        "    # Pooling size correction due to the resolution multiplier parameter\n",
        "    pool_size = int(np.round(7*ro))\n",
        "    x = AveragePooling2D(padding='valid',pool_size=(pool_size,pool_size),strides=(1,1))(x)    \n",
        "    \n",
        "    x = Conv2D(filters=num_units,kernel_size=(1,1),strides=(1,1), padding='same')(x)\n",
        "    \n",
        "    output = Reshape((num_units,))(Activation(activation='softmax')(x))\n",
        "    \n",
        "    return Model(inputs,output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISIJZrqzQo6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO1uBKlDSMXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 1\n",
        "ro = 1\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "target_sz = int(img_size * ro)\n",
        "\n",
        "batch_sz = 32\n",
        "\n",
        "epo = 200\n",
        "\n",
        "image_generator = ImageDataGenerator(rotation_range=15,\n",
        "                                      rescale=1./255,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.1,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "train_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Treinamento',\n",
        "                                                     target_size=(target_sz,target_sz),\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_sz,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True)\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Teste',\n",
        "                                                     target_size=(target_sz,target_sz),\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_sz,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLALd9dcS0MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v1 = MobileNetV1((img_size,img_size,3),num_units=2,alp=alpha,ro=ro,dropout_perc=0.2)\n",
        "\n",
        "optimizer = Adam(lr=0.001)\n",
        "\n",
        "model_v1.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_check_point_v1 = ModelCheckpoint(filepath='/content/gdrive/My Drive/Colab Notebooks/Experimento 2/model_mb_v1.hdf5',monitor='val_loss',verbose=1,save_best_only=False,save_weights_only=False)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=10,verbose=1,min_lr=0.0001)\n",
        "\n",
        "step_size_train = train_generator.n/train_generator.batch_size\n",
        "step_size_test = test_generator.n/test_generator.batch_size\n",
        "\n",
        "history_train_v1 = model_v1.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=step_size_train,\n",
        "                    epochs=epo, validation_data=test_generator,validation_steps=step_size_test,\n",
        "                    workers=8,\n",
        "                    use_multiprocessing=False,\n",
        "                    callbacks=[reduce_lr])\n",
        "\n",
        "model_v1.save('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/model_mb_v1_final.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYNBsrwW28mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "hist_df_v1 = pd.DataFrame(history_train_v1.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0rOTSwJ4cUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/history_mobilenet_v1.json',mode='w') as f:\n",
        "  hist_df_v1.to_json(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfUtPMO8png",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "mb_v1 = load_model('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/model_mb_v1_final.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsoWLz-397-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TXT_VXA-gAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_train_v1.history['loss'],c='r',label='Training loss')\n",
        "plt.plot(history_train_v1.history['val_loss'],c='b',label='Validation loss')\n",
        "plt.title('Loss MobileNet V1')\n",
        "plt.legend()\n",
        "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/loss_mbnet_v1.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goBR7XBm_hyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_train_v1.history['acc'],c='r',label='Training accuracy')\n",
        "plt.plot(history_train_v1.history['val_acc'],c='b',label='Validation accuracy')\n",
        "plt.title('Accuracy MobileNet V1')\n",
        "plt.legend()\n",
        "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/accuracy_mbnet_v1.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR54yhAEKgnT",
        "colab_type": "code",
        "outputId": "ae2cb1a5-2bce-49b1-8de7-791ef96e26a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Teste',\n",
        "                                                     target_size=(target_sz,target_sz),\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_sz,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 822 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--uL4TPQGGk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "y_pred = mb_v1.predict_generator(test_generator,workers=8,steps=step_size_test)\n",
        "y_pred = np.argmax(y_pred,axis=1)\n",
        "y_true = test_generator.classes\n",
        "target_names = ['A320','B737']\n",
        "print(confusion_matrix(y_true,y_pred))\n",
        "print(classification_report(y_true,y_pred,target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE44T4URR6bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img('/content/gdrive/My Drive/Imagens/Airplane models/Validação/B737/boeing_737_700_566386.jpg',target_size=(target_sz,target_sz))\n",
        "x = image.img_to_array(img)/255.\n",
        "\n",
        "x = x.reshape((-1,target_sz,target_sz,3))\n",
        "\n",
        "pred = mb_v1.predict(x)\n",
        "\n",
        "predicted_class_index = np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (test_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "prediction = [labels[k] for k in predicted_class_index]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img)\n",
        "plt.title('Airplane model: '+str(prediction))\n",
        "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/B737_4.jpg')\n",
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}